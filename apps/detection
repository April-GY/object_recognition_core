#!/usr/bin/env python
from argparse import ArgumentParser
from ecto_object_recognition import tod_detection
from ecto_opencv import highgui, calib
from object_recognition.common.filters.masker import Masker
from object_recognition.common.io.ros.source import BagReader
from object_recognition.common.io.sink import Sink
from object_recognition.common.io.source import Source
from object_recognition.common.utils import json_helper
from object_recognition.common.utils.training_detection_args import read_arguments
from object_recognition.tod.detector import TodDetector, TodDetectorLoader
import ecto
import ecto_geometry_msgs
import ecto_ros
import sys

DEBUG = False

########################################################################################################################

if __name__ == '__main__':
    plasm = ecto.Plasm()

    parser = ArgumentParser()

    # add arguments for the source and sink
    Sink.add_arguments(parser)

    params, args, pipeline_params, do_display, db_dict, db = read_arguments(parser)
 
    # TODO handle this properly...
    ecto_ros.init(sys.argv, "ecto_node")

    source = Source.parse_arguments(params['source'])
    

    sink = Sink.parse_arguments(args, db, params['object_ids'])
    
    # define the input
    if 0:
        bag_reader = BagReader(plasm, dict(image=ecto_sensor_msgs.Bagger_Image(topic_name='image_mono'),
                           camera_info=ecto_sensor_msgs.Bagger_CameraInfo(topic_name='camera_info'),
                           point_cloud=ecto_sensor_msgs.Bagger_PointCloud2(topic_name='points'),
                           ), options.bag)

        # connect to the model computation
        point_cloud_to_mat = tod_detection.PointCloudToMat()
        plasm.connect(bag_reader['image'] >> tod_detector['image'],
                      bag_reader['point_cloud'] >> point_cloud_to_mat['point_cloud'],
                      point_cloud_to_mat['points'] >> tod_detector['points'])

    # define the different pipelines
    for pipeline_param in pipeline_params:
        if pipeline_param['type'] == 'TOD':
            # create the loader and detector
            loader = TodDetectorLoader(collection_models = db_dict['collection'],
                                       db_json_params=json_helper.dict_to_cpp_json_str(db_dict),
                                       object_ids=params['object_ids'],
                                       feature_descriptor_params=json_helper.dict_to_cpp_json_str(pipeline_param['feature_descriptor']))
            detector = TodDetector(feature_descriptor_params=pipeline_param['feature_descriptor'],
                                   guess_params=pipeline_param['guess'], search_params=pipeline_param['search'],
                                   display=do_display)
            plasm.connect(loader['descriptors','features3d','spans','id_correspondences','do_update'] >>
                          detector['descriptors_db','features3d_db','spans','id_correspondences','do_update'])

        # Connect the detector to the source
        for key in source.outputs.iterkeys():
            if key in detector.inputs.keys():
                plasm.connect(source[key] >> detector[key])

        # define the different outputs
        # TODO, they should all be connected to a merger first
        plasm.connect(detector['object_ids', 'Rs', 'Ts'] >> sink['object_ids', 'Rs', 'Ts'])

    # make sure that we also give the image_message, in case we want to publish a topic
    if 'image_message' in sink.inputs and 'image_message' in source.outputs:
        plasm.connect(source['image_message'] >> sink['image_message'])

    # Display the different poses
    if do_display:
        pose_view = highgui.imshow(name="Pose")
        pose_drawer = calib.PosesDrawer()

        # draw the poses
        plasm.connect(source['image', 'K'] >> pose_drawer['image', 'K'],
                          detector['Rs', 'Ts'] >> pose_drawer['Rs', 'Ts'],
                          pose_drawer['output'] >> pose_view['image']
                          )

    # display DEBUG data if needed
    if DEBUG:
        print plasm.viz()
        ecto.view_plasm(plasm)

    print >> open('detection.dot', 'wt'), plasm.viz()

    # execute the pipeline
    sched = ecto.schedulers.Threadpool(plasm)
    sched.execute()
